{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 추가 \n",
    "- pip install requests\n",
    "- pip install beautifulsoup4\n",
    "\n",
    "[질의]\n",
    "- https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=chatgpt 에서 a.news_tit 부분에 제목들을 추출하는 python 크롤링 스크립트를 \n",
    "- 요소 선택\n",
    "- .select 사용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F.T.C. Opens Investigation Into ChatGPT Maker Over Technology’s Potenti...\n",
      "조선대 '2023 진로캠프 Design the Future with ChatGPT' 프로그램 성료\n",
      "휴넷, 오는 20일 ‘ChatGPT’ 주제로 라이브 세미나 개최\n",
      "Help! My Boss Won’t Stop Using ChatGPT\n",
      "정선군의회, 부패방지 및 ChatGPT 교육 눈길\n",
      "천안교육지원청, 초중고 교사 대상… ChatGPT 활용 수업·AI윤리 연수\n",
      "[The 초점]ChatGPT와 의료기술\n",
      "일론 머스크, ChatGPT 대항마로 새로운 AI 회사 설립\n",
      "챗GPT·바비·여자 축구… 2023년 가장 인기있는 브랜드는?\n",
      "OpenAI FTC Investigation\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=chatgpt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "news_titles = soup.select(\".news_tit\")\n",
    "\n",
    "for title in news_titles:\n",
    "    print(title.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[질의]\n",
    "- 위의 결과를 CSV 파일로 저장해줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=chatgpt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "news_titles = soup.select(\".news_tit\")\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open('news_titles.csv', mode='w', encoding='utf-8', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow(['Title'])\n",
    "\n",
    "    # Write the news titles\n",
    "    for title in news_titles:\n",
    "        writer.writerow([title.text.strip()])\n",
    "\n",
    "print(\"CSV file has been created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81eef19b52451e11e3f8bf6bc518dd5f147d5a651198624c9c211c83ec7c4923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
