{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=chatgpt 에서 a.news_tit 부분에 제목들을 추출하는 python 크롤링 스크립트를 작성해줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인천시 교육청, ‘ChatGPT시대의 인공지능교육’ 세미나 개최\n",
      "김동연 경기지사 \"GPT 등 첨단기술 가장 먼저 적용할 것\"\n",
      "너무 서둘렀나…카카오판 GPT 챗봇 ‘다다음’ 하루 만에 ‘멈춤’\n",
      "“챗GPT 써봤다”…X세대가 제일 적극적, MZ 세대 바짝 뒤따라\n",
      "국민 3명 중 1명 \"챗GPT 써봤다…아이디어 얻고 대필·코딩까지\"\n",
      "Korea start-ups upgrade apps by plugging into ChatGPT\n",
      "ChatGPT sparks trend in publication and sales of related books\n",
      "자체 모델 있는데…카카오가 ‘GPT 대여’ 오해받는 이유 [이코노Y]\n",
      "동명대 시각디자인학과 선배들이 'ChatGPT/생성AI' 로 후배들 가르친다\n",
      "“챗GPT 외면하면 ‘직업을 잃지 않을 기회’를 놓치게 될 것”\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=chatgpt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "news_titles = soup.select(\".news_tit\")\n",
    "\n",
    "for title in news_titles:\n",
    "    print(title.text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 CSV 파일로 저장해줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=chatgpt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "news_titles = soup.select(\".news_tit\")\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open('news_titles.csv', mode='w', encoding='utf-8', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow(['Title'])\n",
    "\n",
    "    # Write the news titles\n",
    "    for title in news_titles:\n",
    "        writer.writerow([title.text.strip()])\n",
    "\n",
    "print(\"CSV file has been created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81eef19b52451e11e3f8bf6bc518dd5f147d5a651198624c9c211c83ec7c4923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
